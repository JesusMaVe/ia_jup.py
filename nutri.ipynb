{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food-101: Entrenamiento del Modelo\n",
    "\n",
    "**Objetivo:** Entrenar un modelo de clasificación de 101 tipos de alimentos usando Transfer Learning con MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros basicos\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5  # Empezar con pocas epocas\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar datos y crear pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: 101\n",
      "Training samples: 75750\n",
      "Validation samples: 25250\n"
     ]
    }
   ],
   "source": [
    "# Cargar Food-101 dataset\n",
    "(train_ds, val_ds), info = tfds.load(\n",
    "    'food101',\n",
    "    split=['train', 'validation'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "class_names = info.features['label'].names\n",
    "num_classes = len(class_names)\n",
    "print(f'Clases: {num_classes}')\n",
    "print(f'Training samples: {info.splits[\"train\"].num_examples}')\n",
    "print(f'Validation samples: {info.splits[\"validation\"].num_examples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de preprocesamiento y augmentacion\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image, training=True)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipelines creados\n"
     ]
    }
   ],
   "source": [
    "# Crear pipelines de datos\n",
    "train_dataset = (\n",
    "    train_ds\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(1000)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_dataset = (\n",
    "    val_ds\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "print('Pipelines creados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch de imagenes: (32, 224, 224, 3)\n",
      "Batch de labels: (32,)\n",
      "Rango de valores: [0.00, 1.00]\n"
     ]
    }
   ],
   "source": [
    "# Verificar un batch\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f'Batch de imagenes: {images.shape}')\n",
    "    print(f'Batch de labels: {labels.shape}')\n",
    "    print(f'Rango de valores: [{tf.reduce_min(images):.2f}, {tf.reduce_max(images):.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crear modelo (Transfer Learning con MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Modelo base cargado: MobileNetV2\n",
      "Pesos congelados: True\n"
     ]
    }
   ],
   "source": [
    "# Modelo base: MobileNetV2 preentrenado en ImageNet\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Congelar el modelo base para transfer learning\n",
    "base_model.trainable = False\n",
    "\n",
    "print('Modelo base cargado: MobileNetV2')\n",
    "print(f'Pesos congelados: {not base_model.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │       \u001b[38;5;34m129,381\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,387,365</span> (9.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,387,365\u001b[0m (9.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construir modelo completo\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compilar y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo compilado con adam optimizer\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('Modelo compilado con adam optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando por 5 epocas...\n",
      "Epoch 1/5\n",
      "\u001b[1m1738/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:17\u001b[0m 314ms/step - accuracy: 0.3145 - loss: 2.9605"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "print(f'Entrenando por {EPOCHS} epocas...')\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizar entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar accuracy y loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Train')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('Accuracy por Epoca')\n",
    "ax1.set_xlabel('Epoca')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Train')\n",
    "ax2.plot(history.history['val_loss'], label='Validation')\n",
    "ax2.set_title('Loss por Epoca')\n",
    "ax2.set_xlabel('Epoca')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluar modelo en validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en el conjunto de validacion\n",
    "test_loss, test_acc = model.evaluate(val_dataset)\n",
    "print(f'\\nValidation Loss: {test_loss:.4f}')\n",
    "print(f'Validation Accuracy: {test_acc:.4f}')\n",
    "print(f'\\nMejora sobre random (1/{num_classes}): {test_acc / (1/num_classes):.1f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones en validacion\n",
    "print('Generando predicciones...')\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_dataset:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(f'Predicciones generadas: {len(y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analizar resultados (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusion para las primeras 20 clases (para visualizacion)\n",
    "top_n = 20\n",
    "mask = (y_true < top_n) & (y_pred < top_n)\n",
    "y_true_top = y_true[mask]\n",
    "y_pred_top = y_pred[mask]\n",
    "\n",
    "cm = confusion_matrix(y_true_top, y_pred_top, labels=range(top_n))\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix (Top {top_n} clases)')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(top_n)\n",
    "plt.xticks(tick_marks, [class_names[i][:15] for i in range(top_n)], rotation=90)\n",
    "plt.yticks(tick_marks, [class_names[i][:15] for i in range(top_n)])\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicho')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/confusion_matrix_top20.png')\n",
    "plt.show()\n",
    "\n",
    "print(f'Diagonal (predicciones correctas): {np.diag(cm).sum()} / {cm.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    target_names=class_names,\n",
    "    digits=3\n",
    ")\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(report)\n",
    "\n",
    "# Guardar reporte\n",
    "with open('results/classification_report.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizar predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener algunas imagenes con sus predicciones\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "sample_predictions = []\n",
    "\n",
    "for images, labels in val_dataset.take(3):\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    sample_images.extend(images.numpy())\n",
    "    sample_labels.extend(labels.numpy())\n",
    "    sample_predictions.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Encontrar predicciones correctas e incorrectas\n",
    "correct_indices = [i for i in range(len(sample_labels)) if sample_labels[i] == sample_predictions[i]]\n",
    "incorrect_indices = [i for i in range(len(sample_labels)) if sample_labels[i] != sample_predictions[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar predicciones correctas\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(min(9, len(correct_indices))):\n",
    "    idx = correct_indices[i]\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(sample_images[idx])\n",
    "    plt.title(f'Correcto: {class_names[sample_labels[idx]][:15]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Predicciones Correctas', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/correct_predictions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar predicciones incorrectas\n",
    "if len(incorrect_indices) > 0:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(min(9, len(incorrect_indices))):\n",
    "        idx = incorrect_indices[i]\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(sample_images[idx])\n",
    "        plt.title(f'Real: {class_names[sample_labels[idx]][:12]}\\nPred: {class_names[sample_predictions[idx]][:12]}', \n",
    "                  fontsize=9)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Predicciones Incorrectas', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/incorrect_predictions.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No hay predicciones incorrectas en la muestra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar todo (modelo + resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "model.save('models/food_model_v1.h5')\n",
    "print('Modelo guardado en: models/food_model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar historial de entrenamiento\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('results/training_history.csv', index=False)\n",
    "print('Historial guardado en: results/training_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar matriz de confusion completa\n",
    "cm_full = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
    "cm_df = pd.DataFrame(cm_full, index=class_names, columns=class_names)\n",
    "cm_df.to_csv('results/confusion_matrix_full.csv')\n",
    "print('Confusion matrix guardada en: results/confusion_matrix_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('RESUMEN DEL ENTRENAMIENTO')\n",
    "print('='*60)\n",
    "print(f'Modelo: MobileNetV2 + Transfer Learning')\n",
    "print(f'Dataset: Food-101 ({num_classes} clases)')\n",
    "print(f'Epocas: {EPOCHS}')\n",
    "print(f'Batch size: {BATCH_SIZE}')\n",
    "print(f'\\nResultados:')\n",
    "print(f'  Training Accuracy:   {history.history[\"accuracy\"][-1]:.4f}')\n",
    "print(f'  Validation Accuracy: {test_acc:.4f}')\n",
    "print(f'  Training Loss:       {history.history[\"loss\"][-1]:.4f}')\n",
    "print(f'  Validation Loss:     {test_loss:.4f}')\n",
    "print(f'\\nMejora sobre random: {test_acc / (1/num_classes):.1f}x')\n",
    "print('='*60)\n",
    "print('\\nProximos pasos:')\n",
    "print('  1. Entrenar mas epocas (10-15)')\n",
    "print('  2. Fine-tuning (descongelar capas del base_model)')\n",
    "print('  3. Probar modelos mas grandes (EfficientNet)')\n",
    "print('  4. Analizar clases con peor performance')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
